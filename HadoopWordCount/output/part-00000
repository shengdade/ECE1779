!=	1
%s	1
(args.length	1
(tokenizer.hasMoreTokens())	1
(values.hasNext())	1
-1;	1
0;	2
2)	1
<input>	1
<output>\n",	1
=	8
@Override	1
Configured	1
Count");	1
Exception	2
FileInputFormat.addInputPath(conf,	1
FileOutputFormat.setOutputPath(conf,	1
IOException	2
IntWritable	1
IntWritable(1);	1
IntWritable(sum));	1
IntWritable,	1
IntWritable>	4
Iterator<IntWritable>	1
JobClient.runJob(conf);	1
JobConf	1
JobConf(getConf(),	1
MapReduceBase	2
Mapper<LongWritable,	1
OutputCollector<Text,	2
Path(args[0]));	1
Path(args[1]));	1
Reducer<Text,	1
Reporter	2
String	1
StringTokenizer	1
StringTokenizer(line);	1
System.err.printf("Usage:	1
System.exit(exitCode);	1
Text	2
Text();	1
Text,	3
Tool	1
ToolRunner.printGenericCommandUsage(System.err);	1
ToolRunner.run(new	1
WordCountDriver	1
WordCountDriver(),	1
WordCountMapper	1
WordCountReducer	1
[generic	1
args)	2
args);	1
class	3
conf	1
conf.setCombinerClass(WordCountReducer.class);	1
conf.setJobName("Word	1
conf.setMapperClass(WordCountMapper.class);	1
conf.setNumReduceTasks(1);	1
conf.setOutputKeyClass(Text.class);	1
conf.setOutputValueClass(IntWritable.class);	1
conf.setReducerClass(WordCountReducer.class);	1
exitCode	1
extends	3
final	1
getClass());	1
getClass().getSimpleName());	1
if	1
implements	3
import	22
int	3
java.io.IOException;	2
java.util.Iterator;	1
java.util.StringTokenizer;	1
key,	2
line	1
main(String[]	1
map(LongWritable	1
new	7
one	1
one);	1
options]	1
org.apache.hadoop.conf.*;	1
org.apache.hadoop.fs.Path;	1
org.apache.hadoop.io.*;	1
org.apache.hadoop.io.IntWritable;	2
org.apache.hadoop.io.LongWritable;	1
org.apache.hadoop.io.Text;	2
org.apache.hadoop.mapred.*;	1
org.apache.hadoop.mapred.MapReduceBase;	2
org.apache.hadoop.mapred.Mapper;	1
org.apache.hadoop.mapred.OutputCollector;	2
org.apache.hadoop.mapred.Reducer;	1
org.apache.hadoop.mapred.Reporter;	2
org.apache.hadoop.util.*;	1
output,	2
output.collect(key,	1
output.collect(word,	1
private	2
public	7
reduce(Text	1
reporter)	2
return	2
run(String[]	1
static	2
sum	2
throws	4
tokenizer	1
value,	1
value.toString();	1
values,	1
values.next().get();	1
void	3
while	2
word	1
word.set(tokenizer.nextToken());	1
{	10
}	10
